{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert title here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aILwSmo-H7Xo"
   },
   "source": [
    "# Names\n",
    "\n",
    "\n",
    "- Eric Lin\n",
    "- Cecilia Martinez\n",
    "- Jared Singletary\n",
    "- Finn St-John"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TUIEekyH7Xo"
   },
   "source": [
    "# Abstract \n",
    "We will investigate the connection between features of a movie and its rating on the popular movie reviews website Rotten Tomatoes. This website classifies each movie as one of three categories: rotten, fresh, and certified fresh. We plan to use the non-cinematic features of movies to classify them into one of these three categories. Each data point will represent a movie and many of its characteristics. These features include things like genre, release date, runtime, etc. Almost all of these features are nominal or interval. We will be performing classification on our test data to predict the Rotten Tomatoes status of a movie. The status includes the aforementioned three categories. For model selection, we will perform grid-search cross validation and select the model with the best generalization. Since neither false positives nor false negatives pose more risk than the other in the context of our problem, we will evaluate the effectiveness of our model primarily using its f1 score, as this provides a metric that balances the impact of false negatives and false positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oI08l4nyH7Xp"
   },
   "source": [
    "# Background\n",
    "\n",
    "Movie ratings are an important aspect of the film industry, with many consumers relying on them to guide their viewing decisions. Rotten Tomatoes is a popular website that provides ratings based on the percentage of positive reviews for a given movie. These ratings are divided into three categories: rotten for scores below 60%, fresh for scores above 60%, and certified fresh for scores above 75% and at least 5 top critic reviews. Additionally, the website includes an audience score as a separate metric<sup id=\"cite_ref-1\"><a href=\"#cite_note-1\">[1]</a></sup>. Despite the popularity of such rating systems, recent research has raised questions about their accuracy in reflecting the opinions of the general public.\n",
    "\n",
    "In a recent study<sup id=\"cite_ref-2\"><a href=\"#cite_note-2\">[2]</a></sup>, researchers found that movie rating scores on Rotten Tomatoes do not necessarily align with the sentiment of audience reviews. This highlights the need for a more nuanced approach to understanding audience preferences. Furthermore, movie popularity can vary significantly across genres, with certain genres like horror, comedy, mystery, and action performing poorly compared to others such as documentary, classics, and animation<sup id=\"cite_ref-3\"><a href=\"#cite_note-3\">[3]</a></sup>. These differences in popularity may impact the effectiveness of a machine learning algorithm trained on movie ratings data, suggesting the need for careful consideration of genre in the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6OwyI53H7Xp"
   },
   "source": [
    "# Problem Statement\n",
    "\n",
    "The problem that our project is trying to solve is predicting the rotten tomatoes rating for a movie based on movie features including genre, release date, runtime, and content rating. We will do this by using machine learning algorithms like a random forest classifier and logistic regression to predict if a movie will receive a \"fresh\" rotten tomato score or a \"rotten\" score. \n",
    "\n",
    "The dataset we use makes this very much quantifiable, although certain variables are categorical and must therefore be either one-hot encoded or ordinally encoded so that we can work with it mathematically. We will divide our dataset up into 2/3 training data and 1/3 testing data and then use the metric of \"Precision\" to determine the success of our algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Since we are trying to do an analysis of movies and how their features relate with their reviews, an ideal dataset for our project will allow us to compare several movie features with their review scores. \n",
    "\n",
    "Rotten Tomatoes Movies dataset\n",
    "- https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset?select=rotten_tomatoes_movies.csv\n",
    "- This dataset has 17,712 observations and 22 variables per observation. \n",
    "- An observation in this dataset describes a single movie with many pieces of information about it.\n",
    "- Some important variables are the rotten tomatoes score, the genre of the movie, and the director. \n",
    "- Since there is a good amount of categorical variables like genre and director, we will likely need to use one-hot encoding to clean up that data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in our rotten tomatoes csv and select only the columns with the information we have deemed to be critical to our machine learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>genres</th>\n",
       "      <th>directors</th>\n",
       "      <th>runtime</th>\n",
       "      <th>tomatometer_status</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_top_critics_count</th>\n",
       "      <th>tomatometer_fresh_critics_count</th>\n",
       "      <th>tomatometer_rotten_critics_count</th>\n",
       "      <th>original_release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>PG</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>Chris Columbus</td>\n",
       "      <td>119.0</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>2010-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please Give</td>\n",
       "      <td>R</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Nicole Holofcener</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Certified-Fresh</td>\n",
       "      <td>87.0</td>\n",
       "      <td>44</td>\n",
       "      <td>123</td>\n",
       "      <td>19</td>\n",
       "      <td>2010-04-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>Blake Edwards</td>\n",
       "      <td>122.0</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>1979-10-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 Angry Men (Twelve Angry Men)</td>\n",
       "      <td>NR</td>\n",
       "      <td>Classics, Drama</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Certified-Fresh</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1957-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20,000 Leagues Under The Sea</td>\n",
       "      <td>G</td>\n",
       "      <td>Action &amp; Adventure, Drama, Kids &amp; Family</td>\n",
       "      <td>Richard Fleischer</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>1954-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         movie_title content_rating  \\\n",
       "0  Percy Jackson & the Olympians: The Lightning T...             PG   \n",
       "1                                        Please Give              R   \n",
       "2                                                 10              R   \n",
       "3                    12 Angry Men (Twelve Angry Men)             NR   \n",
       "4                       20,000 Leagues Under The Sea              G   \n",
       "\n",
       "                                              genres          directors  \\\n",
       "0  Action & Adventure, Comedy, Drama, Science Fic...     Chris Columbus   \n",
       "1                                             Comedy  Nicole Holofcener   \n",
       "2                                    Comedy, Romance      Blake Edwards   \n",
       "3                                    Classics, Drama       Sidney Lumet   \n",
       "4           Action & Adventure, Drama, Kids & Family  Richard Fleischer   \n",
       "\n",
       "   runtime tomatometer_status  tomatometer_rating  \\\n",
       "0    119.0             Rotten                49.0   \n",
       "1     90.0    Certified-Fresh                87.0   \n",
       "2    122.0              Fresh                67.0   \n",
       "3     95.0    Certified-Fresh               100.0   \n",
       "4    127.0              Fresh                89.0   \n",
       "\n",
       "   tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
       "0                             43                               73   \n",
       "1                             44                              123   \n",
       "2                              2                               16   \n",
       "3                              6                               54   \n",
       "4                              5                               24   \n",
       "\n",
       "   tomatometer_rotten_critics_count original_release_date  \n",
       "0                                76            2010-02-12  \n",
       "1                                19            2010-04-30  \n",
       "2                                 8            1979-10-05  \n",
       "3                                 0            1957-04-13  \n",
       "4                                 3            1954-01-01  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('data/rotten_tomatoes_movies.csv')\n",
    "critical_columns = ['movie_title', 'content_rating', 'genres', 'directors', 'runtime', 'tomatometer_status', \n",
    "                    'tomatometer_rating', 'tomatometer_top_critics_count', 'tomatometer_fresh_critics_count',\n",
    "                    'tomatometer_rotten_critics_count', 'original_release_date']\n",
    "movies = movies[critical_columns]\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the genre of the movie will be an important predictor, so we collect all the different genres into a set so we can see the unique values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Musical & Performing Arts', 'Kids & Family', 'Romance', 'Science Fiction & Fantasy', 'Documentary', 'Action & Adventure', 'Special Interest', 'Drama', 'Anime & Manga', 'Faith & Spirituality', 'Western', 'Gay & Lesbian', 'Art House & International', 'Classics', 'Comedy', 'Animation', 'Mystery & Suspense', 'Sports & Fitness', 'Television', 'Horror', 'Cult Movies'}\n"
     ]
    }
   ],
   "source": [
    "genre_set = set()\n",
    "for i in movies['genres']:\n",
    "    if (type(i) == str):\n",
    "        for j in i.split(','):\n",
    "            j = j.strip()\n",
    "            genre_set.add(j)\n",
    "print(genre_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in how many null values are in our csv because they can cause errors in our machine learning algorithms. We look through the columns and see how many null values they all have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_title 0\n",
      "content_rating 0\n",
      "genres 19\n",
      "directors 194\n",
      "runtime 314\n",
      "tomatometer_status 44\n",
      "tomatometer_rating 44\n",
      "tomatometer_top_critics_count 0\n",
      "tomatometer_fresh_critics_count 0\n",
      "tomatometer_rotten_critics_count 0\n",
      "original_release_date 1166\n"
     ]
    }
   ],
   "source": [
    "for i in movies.columns:\n",
    "    print(i,movies[i].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there aren't very many null values across our columns, we will just drop all the null values to avoid any problems later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16208, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = movies.dropna()\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genres list is a categorigal variable with no order. So we one hot encoded it.\n",
    "To one hot encode the genres, first made genres into a new genres list. Then, applied Series to each 'genres list' element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres list'] = movies['genres'].str.split(', ', expand=False)\n",
    "genres_series = movies['genres list'].apply(pd.Series).stack()\n",
    "genres_encoded = pd.get_dummies(genres_series).groupby(level=0).sum()\n",
    "# movies = pd.concat([movies, genres_encoded], axis=1)\n",
    "\n",
    "genres_list = []\n",
    "for i in genres_encoded.index:\n",
    "    row_list = genres_encoded.loc[i, :].values.flatten().tolist()\n",
    "    genres_list.append(row_list)\n",
    "\n",
    "movies['genres_encoded'] = genres_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratings have an order to it, so we turned it into an ordinal numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = {'G': 0, 'PG': 1, 'PG-13': 2, 'R': 3, 'NR': 4, 'NC17': 5}\n",
    "\n",
    "movies['content_rating_id'] = movies['content_rating'].map(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We turned original release date into a pandas date time object so we can easily compare it to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['original_release_date'] = pd.to_datetime(movies['original_release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>content_rating_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_encoded</th>\n",
       "      <th>directors</th>\n",
       "      <th>runtime</th>\n",
       "      <th>original_release_date</th>\n",
       "      <th>tomatometer_status</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_top_critics_count</th>\n",
       "      <th>tomatometer_fresh_critics_count</th>\n",
       "      <th>tomatometer_rotten_critics_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Chris Columbus</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please Give</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Nicole Holofcener</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>Certified-Fresh</td>\n",
       "      <td>87.0</td>\n",
       "      <td>44</td>\n",
       "      <td>123</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Blake Edwards</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1979-10-05</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 Angry Men (Twelve Angry Men)</td>\n",
       "      <td>NR</td>\n",
       "      <td>4</td>\n",
       "      <td>Classics, Drama</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1957-04-13</td>\n",
       "      <td>Certified-Fresh</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20,000 Leagues Under The Sea</td>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "      <td>Action &amp; Adventure, Drama, Kids &amp; Family</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>Richard Fleischer</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1954-01-01</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         movie_title content_rating  \\\n",
       "0  Percy Jackson & the Olympians: The Lightning T...             PG   \n",
       "1                                        Please Give              R   \n",
       "2                                                 10              R   \n",
       "3                    12 Angry Men (Twelve Angry Men)             NR   \n",
       "4                       20,000 Leagues Under The Sea              G   \n",
       "\n",
       "   content_rating_id                                             genres  \\\n",
       "0                  1  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "1                  3                                             Comedy   \n",
       "2                  3                                    Comedy, Romance   \n",
       "3                  4                                    Classics, Drama   \n",
       "4                  0           Action & Adventure, Drama, Kids & Family   \n",
       "\n",
       "                                      genres_encoded          directors  \\\n",
       "0  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...     Chris Columbus   \n",
       "1  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  Nicole Holofcener   \n",
       "2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      Blake Edwards   \n",
       "3  [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...       Sidney Lumet   \n",
       "4  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...  Richard Fleischer   \n",
       "\n",
       "   runtime original_release_date tomatometer_status  tomatometer_rating  \\\n",
       "0    119.0            2010-02-12             Rotten                49.0   \n",
       "1     90.0            2010-04-30    Certified-Fresh                87.0   \n",
       "2    122.0            1979-10-05              Fresh                67.0   \n",
       "3     95.0            1957-04-13    Certified-Fresh               100.0   \n",
       "4    127.0            1954-01-01              Fresh                89.0   \n",
       "\n",
       "   tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
       "0                             43                               73   \n",
       "1                             44                              123   \n",
       "2                              2                               16   \n",
       "3                              6                               54   \n",
       "4                              5                               24   \n",
       "\n",
       "   tomatometer_rotten_critics_count  \n",
       "0                                76  \n",
       "1                                19  \n",
       "2                                 8  \n",
       "3                                 0  \n",
       "4                                 3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reordering the columns\n",
    "reordered_columns = ['movie_title', 'content_rating', 'content_rating_id', 'genres', 'genres_encoded', 'directors',\n",
    "                    'runtime', 'original_release_date', 'tomatometer_status', 'tomatometer_rating', \n",
    "                    'tomatometer_top_critics_count', 'tomatometer_fresh_critics_count', 'tomatometer_rotten_critics_count']\n",
    "movies = movies[reordered_columns]\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LY2ho0p3H7Xq"
   },
   "source": [
    "# Proposed Solution\n",
    "\n",
    "We predict that these features, while not completely evident in the content of the movie, will be a large predictor of the movie’s rating. More specifically, we predict that the director will have a large influence on the overall rating given to the movie. Additionally, we predict that certain genres will be rated more highly than others across the board. We believe that a classification model will be able to effectively find a connection between director and rating and genre and rating. We will test each solution using our selected metric: the f1 score of a model. We believe that there is a connection to discover between these non-cinematic characteristics and the rating of the movie, whether it is a large connection or small connection, and therefore believe that a classification model will be able to effectively identify this connection.\n",
    "\n",
    "The classifiers we have tested are support vector machines, logistic regression, and random forest. There are a two things to consider when selecting our model. We must consider the ability of the model to approximate more complex functions, and we must consider the interpretability of the classifier. SVMs, while powerful are not very interpretable. Logistic Regression is less powerful, but more interpretable. \n",
    "\n",
    "After performing grid search cross-validation on these three algorithms, we are most interested in using a random forest classifier.\n",
    "\n",
    "Because we are looking to discover an inherent connection between certain features of our data, we would like to select the most interpretable model. However, because model interpretability scales inversely with model capacity (the amount of functions a model can approximate), we have to balance these two characteristics. Because we need to find a good medium, we are looking into using a random forest classifier. Random forest classifiers comprise many decision trees. Decision trees are some of the most interpretable classifiers available for use. Additionally, because random forests are ensemble learners, it's acceptable to use a less complex model (decision trees, in this case). \n",
    "\n",
    "Using a random forest classifier allows us to get the best of both worlds. Our model will have high interpretability, as well as a high model capacity and high prediction ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QE4rImmoH7Xr"
   },
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "The evaluation model we will use will be based on precision, as it is the most valuable metric to look at in the context of this problem. \n",
    "\n",
    "If a filmmaker were to create a movie based on this machine learning algorithm, spending money, time, and effort on a movie that our model predicted would do well, but then flops in reality (false positive), there would be significantly worse consequences for the filmmaker than a movie that’s expected to do poorly but ends up doing really well (false negative). A false negative would have little effect when actually using our model in practice, as filmmakers rarely have the intention of making a bad movie. As such, maximizing the precision score would minimize the amount of false positives, making a more useful model. \n",
    "\n",
    "Precision = True Positive/(True Positive + False Positive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>content_rating_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>genres_encoded</th>\n",
       "      <th>directors</th>\n",
       "      <th>runtime</th>\n",
       "      <th>original_release_date</th>\n",
       "      <th>tomatometer_status</th>\n",
       "      <th>tomatometer_rating</th>\n",
       "      <th>tomatometer_top_critics_count</th>\n",
       "      <th>tomatometer_fresh_critics_count</th>\n",
       "      <th>tomatometer_rotten_critics_count</th>\n",
       "      <th>status_encoded</th>\n",
       "      <th>binary_tomatometer_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Percy Jackson &amp; the Olympians: The Lightning T...</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "      <td>Action &amp; Adventure, Comedy, Drama, Science Fic...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Chris Columbus</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>49.0</td>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please Give</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Nicole Holofcener</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>Certified-Fresh</td>\n",
       "      <td>87.0</td>\n",
       "      <td>44</td>\n",
       "      <td>123</td>\n",
       "      <td>19</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>3</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Blake Edwards</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1979-10-05</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12 Angry Men (Twelve Angry Men)</td>\n",
       "      <td>NR</td>\n",
       "      <td>4</td>\n",
       "      <td>Classics, Drama</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>Sidney Lumet</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1957-04-13</td>\n",
       "      <td>Certified-Fresh</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20,000 Leagues Under The Sea</td>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "      <td>Action &amp; Adventure, Drama, Kids &amp; Family</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>Richard Fleischer</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1954-01-01</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         movie_title content_rating  \\\n",
       "0  Percy Jackson & the Olympians: The Lightning T...             PG   \n",
       "1                                        Please Give              R   \n",
       "2                                                 10              R   \n",
       "3                    12 Angry Men (Twelve Angry Men)             NR   \n",
       "4                       20,000 Leagues Under The Sea              G   \n",
       "\n",
       "   content_rating_id                                             genres  \\\n",
       "0                  1  Action & Adventure, Comedy, Drama, Science Fic...   \n",
       "1                  3                                             Comedy   \n",
       "2                  3                                    Comedy, Romance   \n",
       "3                  4                                    Classics, Drama   \n",
       "4                  0           Action & Adventure, Drama, Kids & Family   \n",
       "\n",
       "                                      genres_encoded          directors  \\\n",
       "0  [1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...     Chris Columbus   \n",
       "1  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  Nicole Holofcener   \n",
       "2  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      Blake Edwards   \n",
       "3  [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...       Sidney Lumet   \n",
       "4  [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, ...  Richard Fleischer   \n",
       "\n",
       "   runtime original_release_date tomatometer_status  tomatometer_rating  \\\n",
       "0    119.0            2010-02-12             Rotten                49.0   \n",
       "1     90.0            2010-04-30    Certified-Fresh                87.0   \n",
       "2    122.0            1979-10-05              Fresh                67.0   \n",
       "3     95.0            1957-04-13    Certified-Fresh               100.0   \n",
       "4    127.0            1954-01-01              Fresh                89.0   \n",
       "\n",
       "   tomatometer_top_critics_count  tomatometer_fresh_critics_count  \\\n",
       "0                             43                               73   \n",
       "1                             44                              123   \n",
       "2                              2                               16   \n",
       "3                              6                               54   \n",
       "4                              5                               24   \n",
       "\n",
       "   tomatometer_rotten_critics_count status_encoded  binary_tomatometer_status  \n",
       "0                                76      [1, 0, 0]                          0  \n",
       "1                                19      [0, 0, 1]                          1  \n",
       "2                                 8      [0, 1, 0]                          1  \n",
       "3                                 0      [0, 0, 1]                          1  \n",
       "4                                 3      [0, 1, 0]                          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_encoded = pd.get_dummies(movies['tomatometer_status']).groupby(level=0).sum()\n",
    "\n",
    "status_list = []\n",
    "for i in status_encoded.index:\n",
    "    row_list = status_encoded.loc[i, :].values.flatten().tolist()\n",
    "    status_list.append(row_list[::-1])\n",
    "\n",
    "movies['status_encoded'] = status_list\n",
    "\n",
    "# turn tomatometer status into binary so that we can use binary classifiers\n",
    "binary_encoding = []\n",
    "certified_fresh = [0, 0, 1]\n",
    "fresh = [0, 1, 0]\n",
    "# for each one hot encoded list\n",
    "for val in status_list:\n",
    "    # val is fresh or certified fresh\n",
    "    if val in [fresh, certified_fresh]:\n",
    "        binary_encoding.append(1)\n",
    "    else:\n",
    "        binary_encoding.append(0)\n",
    "        \n",
    "movies['binary_tomatometer_status'] = binary_encoding\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create month column\n",
    "movies['original_release_date']\n",
    "\n",
    "movies['original_release_month'] = [d.month for d in movies['original_release_date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some formatting, test estimators on predicting `tomatometer_status` using rating, runtime, release month, and genres.\n",
    "\n",
    "Our selected classifiers include:\n",
    "1. SVM\n",
    "2. Logistic Regression\n",
    "3. Random Forests\n",
    "\n",
    "Each of these can be used as binary classifiers, so they should apply well to our data & problem. This set of algorithms also tests high and low interpretability and high and low complexity/power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['original_release_month', 'genres_encoded', 'runtime', 'content_rating_id']\n",
    "\n",
    "data = np.array(movies[selected_columns])\n",
    "\n",
    "vectorized_data = []\n",
    "for d in data:\n",
    "    data_point = []\n",
    "    for feature in d:\n",
    "        if type(feature) is list:\n",
    "            data_point.extend(feature)\n",
    "        else:\n",
    "            data_point.append(feature)\n",
    "    vectorized_data.append(data_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some classifiers\n",
    "\n",
    "Classifiers and hyperparameters we tested:\n",
    "\n",
    "#### SVM:\n",
    "- C: 0.1, 1, 5, 10, 100\n",
    "- Kernel: linear, RBF\n",
    "\n",
    "#### Logistic Regression:\n",
    "- Penalty: L1, L2\n",
    "- C: 0.01, 0.1, 1, 10\n",
    "- Solver: Liblinear, Saga\n",
    "\n",
    "#### Random Forest:\n",
    "- Number of Estimators: 100, 200, 400, 600\n",
    "- Criterion: Gini, Entropy\n",
    "- Max Depth: 50, 60, 90\n",
    "- Minimum Samples for Split: 2, 7, 9, 12\n",
    "- Max Features: Square-root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import uniform, truncnorm, randint\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(vectorized_data)\n",
    "y = np.array(movies['binary_tomatometer_status'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best(*models):\n",
    "    best = models[0]\n",
    "    for model in models:\n",
    "        # should select best model based on lowest accuracy\n",
    "        if model['score'] < best['score']:\n",
    "            best = model\n",
    "    return best\n",
    "\n",
    "def save_best_model(grid_search, filepath):\n",
    "    new_model = {\n",
    "        'parameters': grid_search.best_params_,\n",
    "        'score': grid_search.best_score_\n",
    "    }\n",
    "    current_best = read_results(filepath)\n",
    "    if current_best != {}:\n",
    "        write_results(filepath, select_best(new_model, current_best))\n",
    "    else:\n",
    "        write_results(filepath, new_model)\n",
    "    \n",
    "def read_results(filepath):\n",
    "    with open(filepath) as f:\n",
    "        content = f.read()\n",
    "        if content == '':\n",
    "            return {}\n",
    "        else:\n",
    "            return json.loads(content)\n",
    "        \n",
    "def write_results(filepath, model):\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(json.dumps(model))\n",
    "        \n",
    "def plot_results(grid_search):\n",
    "    params = grid_search.cv_results_[\"params\"]\n",
    "    ys = grid_search.cv_results_[\"mean_test_score\"]\n",
    "    xs = ['|'.join(str(v) for v in param.values()) for param in params]\n",
    "    yerr = grid_search.cv_results_[\"std_test_score\"]\n",
    "    plt.errorbar(xs, ys, yerr / np.sqrt(grid_search.cv), fmt='.k')\n",
    "    plt.ylabel(\"f1\")\n",
    "    plt.xlabel(\"params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe_gs = Pipeline(steps=[('scaler', StandardScaler()), ('svc', SVC(random_state=42))])\n",
    "\n",
    "svm_param_grid_gs = {\n",
    "    'svc__C': [1, 5, 10, 100],\n",
    "    'svc__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "svm_gscv = GridSearchCV(svm_pipe_gs, svm_param_grid_gs, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msvm_gscv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m save_best_model(svm_gscv, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model_selection_results/SVM.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    251\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 252\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mY:\\Users\\Finn St. John\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    317\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    321\u001b[0m (\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 331\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm_gscv.fit(X_train, y_train)\n",
    "\n",
    "save_best_model(svm_gscv, './model_selection_results/SVM.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(svm_gscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_pipe_gs = Pipeline(steps=[('scaler', StandardScaler()), ('logistic', LogisticRegression(random_state=42))])\n",
    "\n",
    "logistic_param_grid_gs = {\n",
    "    'logistic__penalty': ['l1', 'l2'],\n",
    "    'logistic__C': [0.01, 0.1, 1, 10],\n",
    "    'logistic__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "logistic_gscv = GridSearchCV(logistic_pipe_gs, logistic_param_grid_gs, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_gscv.fit(X_train, y_train)\n",
    "\n",
    "save_best_model(logistic_gscv, './model_selection_results/LogisticRegression.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(logistic_gscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipe_gs = Pipeline(steps=[('scaler', StandardScaler()), ('forest', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "forest_param_grid_gs = {\n",
    "    'forest__n_estimators': [100, 200, 400],\n",
    "    'forest__criterion': ['gini', 'entropy'],\n",
    "    'forest__max_depth': [50, 60, 90],\n",
    "    'forest__min_samples_split': [2, 7, 9, 12],\n",
    "    'forest__max_features': ['sqrt'],\n",
    "    'forest__bootstrap': [True]\n",
    "}\n",
    "\n",
    "forest_gscv = GridSearchCV(forest_pipe_gs, forest_param_grid_gs, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_gscv.fit(X_train, y_train)\n",
    "\n",
    "save_best_model(forest_gscv, './model_selection_results/RandomForest.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(forest_gscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_pipe_rs = Pipeline(steps=[('scaler', StandardScaler()), ('logistic', LogisticRegression(random_state=42))])\n",
    "\n",
    "logistic_param_grid_rs = {\n",
    "    'logistic__penalty': ['l1', 'l2'],\n",
    "    'logistic__C': uniform(0.1, 100),\n",
    "    'logistic__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "logistic_rscv = RandomizedSearchCV(logistic_pipe_rs, logistic_param_grid_rs, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_rscv.fit(X_train, y_train)\n",
    "\n",
    "save_best_model(logistic_rscv, './model_selection_results/LogisticRegression.json')\n",
    "\n",
    "plot_results(logistic_rscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe_rs = Pipeline(steps=[('scaler', StandardScaler()), ('logistic', LogisticRegression(random_state=42))])\n",
    "\n",
    "svm_param_grid_rs = {\n",
    "    'svc__C': randint(1,100),\n",
    "    'svc__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "svm_rscv = RandomizedSearchCV(svm_pipe_rs, svm_param_grid_rs, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rscv.fit(X_train, y_train)svm\n",
    "\n",
    "save_best_model(svm_rscv, './model_selection_results/SVM.json')\n",
    "\n",
    "plot_results(svm_rscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipe_rs = Pipeline(steps=[('scaler', StandardScaler()), ('forest', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "forest_param_grid_rs = {\n",
    "    'forest__n_estimators': randint(50, 800),\n",
    "    'forest__criterion': ['gini', 'entropy'],\n",
    "    'forest__max_depth': randint(30, 100),\n",
    "    'forest__min_samples_split': randint(2,15),\n",
    "    'forest__max_features': ['sqrt'],\n",
    "    'forest__bootstrap': [True]\n",
    "}\n",
    "\n",
    "forest_rscv = GridSearchCV(forest_pipe_rs, forest_param_grid_rs, cv=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_rscv.fit(X_train, y_train)\n",
    "\n",
    "save_best_model(forest_rscv, './model_selection_results/RandomForest.json')\n",
    "\n",
    "plot_results(forest_rscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing other validation methods\n",
    "\n",
    "- Let's try other validation algorithms:\n",
    "  - K-fold cross validation\n",
    "  - RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yBbcJ7MH7Xs"
   },
   "source": [
    "Since the dataset that we are working with is only using publicly available information about Hollywood movies from the Rotten Tomatoes website, our Machine Learning analysis should not end up running into ethical concerns. One consideration we are taking into account is that this dataset has the names of all the movie reviewers in it, which could be an ethical concern if we include their names in our analysis. We’re going to avoid that though by completely ignoring the names of the critics and dropping it from the data since their names are irrelevant to our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech information above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "Since the dataset that we are working with is only using publicly available information about Hollywood movies from the Rotten Tomatoes website, our Machine Learning analysis should not end up running into ethical concerns. One consideration we are taking into account is that this dataset has the names of all the movie reviewers in it, which could be an ethical concern if we include their names in our analysis. We’re going to avoid that though by completely ignoring the names of the critics and dropping it from the data since their names are irrelevant to our project. \n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiAh367ZH7Xu"
   },
   "source": [
    "# Footnotes\n",
    "\n",
    "<div class=\"footnotes\">\n",
    "<hr>\n",
    "<ol>\n",
    "  <li id=\"cite_note-1\">\n",
    "    <span>Liao, E. (2018, December 8). Can We Predict Rotten Tomatoes Ratings? Towards Data Science. <a href=\"https://towardsdatascience.com/can-we-predict-rotten-tomatoes-ratings-8b5f5b7d7eff\">(source)</a></span>\n",
    "    <a href=\"#cite_ref-1\" title=\"Jump back to footnote 1 in the text.\">↩</a>\n",
    "  </li>\n",
    "  <li id=\"cite_note-2\">\n",
    "    <span>Maio, A. (2020, March 4). How Does Rotten Tomatoes Actually Work? Studio Binder. <a href=\"https://www.studiobinder.com/blog/rotten-tomatoes-ratings-system/\">(source)</a></span>\n",
    "    <a href=\"#cite_ref-2\" title=\"Jump back to footnote 2 in the text.\">↩</a>\n",
    "  </li>\n",
    "  <li id=\"cite_note-3\">\n",
    "    <span>Roper, H. (2021, January 20). What makes for a good movie? Towards Data Science. <a href=\"https://towardsdatascience.com/what-makes-for-a-good-movie-8e10896e0f1b\">(source)</a></span>\n",
    "    <a href=\"#cite_ref-3\" title=\"Jump back to footnote 3 in the text.\">↩</a>\n",
    "  </li>\n",
    "</ol>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d97291b28ebc2ff000615131b06cad58c22c64eaea404ca3770ee7587249fb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
